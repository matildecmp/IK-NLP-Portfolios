{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_SDyiQN2cnF"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gsarti/ik-nlp-tutorials/blob/main/notebooks/W2E_Pipelines_Sentence_Transformers.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXzNG7rW2cnH",
        "outputId": "7c01a38a-49ac-44b7-fbd7-f34bb0d14f17",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.40.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Collecting transformers\n",
            "  Using cached transformers-5.1.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
            "  Downloading huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached transformers-5.1.0-py3-none-any.whl (10.3 MB)\n",
            "Downloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m553.3/553.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 0.36.2\n",
            "    Uninstalling huggingface_hub-0.36.2:\n",
            "      Successfully uninstalled huggingface_hub-0.36.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.0\n",
            "    Uninstalling transformers-4.40.0:\n",
            "      Successfully uninstalled transformers-4.40.0\n",
            "Successfully installed huggingface-hub-1.4.1 tokenizers-0.22.2 transformers-5.1.0\n"
          ]
        }
      ],
      "source": [
        "# Run in Colab to install local packages\n",
        "!pip install transformers sentencepiece torch datasets sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Needed to downgrade from Transformers 5.1 to 4.40 to ensure standard 'translation' task compatibility within the pipeline API\n",
        "!pip uninstall -y transformers accelerate\n",
        "!pip install transformers==4.40.0 accelerate==0.30.0 sentencepiece sacremoses"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZKhbnE8CH3J3",
        "outputId": "ba20cf4d-5ea3-4bff-df29-a8cf63cbd618",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 5.1.0\n",
            "Uninstalling transformers-5.1.0:\n",
            "  Successfully uninstalled transformers-5.1.0\n",
            "Found existing installation: accelerate 0.30.0\n",
            "Uninstalling accelerate-0.30.0:\n",
            "  Successfully uninstalled accelerate-0.30.0\n",
            "Collecting transformers==4.40.0\n",
            "  Using cached transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
            "Collecting accelerate==0.30.0\n",
            "  Using cached accelerate-0.30.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.12/dist-packages (0.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.0) (3.20.3)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.40.0)\n",
            "  Using cached huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.0) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.0) (2.32.4)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.0)\n",
            "  Using cached tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.0) (4.67.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (2.9.0+cpu)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from sacremoses) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from sacremoses) (1.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.40.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.40.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.40.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.40.0) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.30.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.30.0) (3.0.3)\n",
            "Using cached transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
            "Using cached accelerate-0.30.0-py3-none-any.whl (302 kB)\n",
            "Using cached huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "Using cached tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Installing collected packages: huggingface-hub, tokenizers, accelerate, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 1.4.1\n",
            "    Uninstalling huggingface_hub-1.4.1:\n",
            "      Successfully uninstalled huggingface_hub-1.4.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.2\n",
            "    Uninstalling tokenizers-0.22.2:\n",
            "      Successfully uninstalled tokenizers-0.22.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.2.2 requires transformers<6.0.0,>=4.41.0, but you have transformers 4.40.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.30.0 huggingface-hub-0.36.2 tokenizers-0.19.1 transformers-4.40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgatzxx02cnI"
      },
      "source": [
        "# ü§ó Pipelines & Sentence Transformers for Semantic Search and QA\n",
        "\n",
        "*This notebook is partly adapted from a tutorial by Wietse De Vries for the IK-NLP course of 2021*\n",
        "\n",
        "The goal of this notebook is to make you practice with some pipeline use-cases and to introduce the [Sentence Transformers](https://sbert.net/) in the context of a concrete example of semantic search and question answering (relevant to the Open-book Question Answering final project).\n",
        "\n",
        "Exercises 1 and 2 of this notebook are mandatory and will be part of your first graded portfolio. Exercise 3 is optional, but we highly recommend you to complete it, especially if you're interested in the Open-book Question Answering final project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhuUXncg2cnJ"
      },
      "source": [
        "## Exercise 1: Using the Fill-mask pipeline for Probing Linguistic Knowledge in mBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWQA3wev2cnJ"
      },
      "source": [
        "As you probably know by now, BERT is a transformed-based, context-sensitive, neural language models that has been trained, among others, on a masked language modeling task, where the model learns to predict what the most likely word is at a a *masked* (hidden) position in the sentence. In a sentence like:\n",
        "\n",
        ">There were several [MASK] with the proposed solution.\n",
        "    \n",
        "the model will learn that the word *problems* or *issues* is more likely at this position than the word *unicorns* or *days*. The model uses both the right and left context of the masked position to make its predictions. Models trained to maximize the probability of predicting the correct masked words learn to represent a good amount of linguistic knowledge as a result of this.\n",
        "\n",
        "A **probe** is a test of a language model aimed at investigating how accurate these predictions are, especially for cases where syntax makes it quite clear that one (form of a) word is correct, and another word is impossible. In the example above, for instance, the masked position can be filled by a plural noun (*problems*) but not by a singular noun (*problem*). If the model makes predictions that respect the linguistic constraints, we have reason to believe that the model is somehow aware of the linguistic structure of the language.\n",
        "\n",
        "While predicting whether the masked position should be filled by a singular or plural noun seems easy in the example above (both *were* and *several* are good predictors of plural), we can try to make the task harder by looking for contexts where the solution requires more careful *attention* to the right words in the context\n",
        "\n",
        ">There were some [MASK] with the proposed solution.\n",
        ">\n",
        ">There could be several [MASK] with the proposed solution.\n",
        ">\n",
        ">There were some unexpected and unforeseen [MASK] with the proposed solution.\n",
        "    \n",
        "In the examples above, the task is made harder by replacing *several* (which is always followed by a plural noun) by *some* (which can be followed by a singular or a plural noun), by replacing *were* (which always heads a sentence with a plural subject) by *could be* (which can head a sentence with a singular or plural subject), and by inserting material between the verb *were* (which indicates that there should be a plural) and the MASK.\n",
        "\n",
        "\n",
        "### Assignment\n",
        "\n",
        "Think of a grammatical phenomenon in a language of your choice, and come up with at least 5 example sentences to probe whether the model makes the correct predictions. Think of cases where the context makes it clear that the mask has to be plural or singular, that a verb has to have a particular form (like plural or singular, or participle or infinitive), that a specific (personal, possessive, reflexive) pronoun has to be used, that an adjective or noun has to have a specific inflection (like in German and more generally in languages with a rich case and/or gender marking system). There is a host of literature on this, see for instance [Marvin and Linzen](https://arxiv.org/abs/1808.09031) (for English) and [Sahin et al](https://www.mitpressjournals.org/doi/full/10.1162/coli_a_00376) (for multilingual probes).\n",
        "\n",
        "### Model\n",
        "\n",
        "The model we will be using for this task is the [multilingual BERT](https://huggingface.co/bert-base-multilingual-cased) model mBERT, that was trained on the Wikipedia text of the 102 largest Wikipedia's. This means that you do not have to choose examples from English, but that you may also present a probe for another language.\n",
        "\n",
        "The following loads the pipeline for doing masked prediction, and load the mBERT model (this may take a minute or so). You can ignore the warning about some weights not being initialized. The pipeline can be used to test masked language model prediction. Given a sequence containing the special token [MASK], the model will predict what the most likely tokens are at that position, using both left and right context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624,
          "referenced_widgets": [
            "b0f988cf7197404faf5aac72ae62e866",
            "9694b1fa14504b5497b823e7de0646e1",
            "fb76fc908fb1469c8d6df54ac197a232",
            "7fe65ccc8bbf4f738f8e1ca5af6e78f3",
            "d629e785c17c4ba69ba00e73b7f394d9",
            "396f6306cc7748b994e1decf7235d496",
            "4feea6cfb86a47e9ae57472fbe39a64a",
            "e996e4bc26c84bafb85f7119b374faf7",
            "633b68242ae94a249851b14a2e5afbd0",
            "ab76d8cb571a4bb381feffd64900529e",
            "a98d84f44ec44ac0b9816ad9d4893068"
          ]
        },
        "id": "b3EilENL2cnK",
        "outputId": "0c3882f6-fd60-4bfa-b84a-9157ce533ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0f988cf7197404faf5aac72ae62e866"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.5272428393363953,\n",
              "  'token': 20390,\n",
              "  'token_str': 'problems',\n",
              "  'sequence': 'There were some unexpected and unforeseen problems with the proposed solution.'},\n",
              " {'score': 0.09590274840593338,\n",
              "  'token': 17850,\n",
              "  'token_str': 'issues',\n",
              "  'sequence': 'There were some unexpected and unforeseen issues with the proposed solution.'},\n",
              " {'score': 0.06644522398710251,\n",
              "  'token': 64557,\n",
              "  'token_str': 'difficulties',\n",
              "  'sequence': 'There were some unexpected and unforeseen difficulties with the proposed solution.'},\n",
              " {'score': 0.016898080706596375,\n",
              "  'token': 73082,\n",
              "  'token_str': 'dealing',\n",
              "  'sequence': 'There were some unexpected and unforeseen dealing with the proposed solution.'},\n",
              " {'score': 0.015166711993515491,\n",
              "  'token': 18107,\n",
              "  'token_str': 'associated',\n",
              "  'sequence': 'There were some unexpected and unforeseen associated with the proposed solution.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "mbert = pipeline('fill-mask', model='bert-base-multilingual-cased')\n",
        "mbert('There were some unexpected and unforeseen [MASK] with the proposed solution.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muxGcPBQ2cnK"
      },
      "source": [
        "By default, the pipe returns the 5 most likely words that could appear at the position of the mask, along with a score. If you want to know specifically whether the model prefers one of two forms, you can give these forms as targets to the pipe, and also print the answer in a more readable form:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "007PQgYX2cnL",
        "outputId": "8cceafed-1d7b-4a72-b336-ac2dfdbe2521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0034\ttoken: challenges\tThere were some unexpected and unforeseen challenges with the proposed solution.\n",
            "0.0001\ttoken: challenge\tThere were some unexpected and unforeseen challenge with the proposed solution.\n"
          ]
        }
      ],
      "source": [
        "def probe(sentence: str, targets: str) :\n",
        "    for res in mbert(sentence,targets=targets) :\n",
        "        print(f\"{res['score']:6.4f}\\ttoken: {res['token_str']}\\t{res['sequence']}\")\n",
        "\n",
        "probe('There were some unexpected and unforeseen [MASK] with the proposed solution.',['challenge','challenges'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyRZz6Q42cnL"
      },
      "source": [
        "> **üí° Interesting Fact**: The same bias that is present towards grammatically correct choices can be observed in other cases, such as racial and gender stereotyping. Much work is currently in process to identify and remove gender and racial biases from learned language embeddings. See the following example and [this recent survey on the topic](https://arxiv.org/abs/2112.14168)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwc22D642cnM",
        "outputId": "5447d4db-2b26-49b2-cae5-8fed6a0741b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['lawyer', 'carpenter', 'doctor', 'waiter', 'mechanic']\n",
            "['nurse', 'waitress', 'teacher', 'maid', 'prostitute']\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-cased\")\n",
        "result = unmasker(\"This man works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"This woman works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdV9X_a52cnM"
      },
      "source": [
        "### Your Turn to Probe\n",
        "\n",
        "Give at least five example sentences with a [MASK] and a list of targets that illustrate a specific grammatical phenomenon in a language of your choice. Describe what the grammatical phenomenon is you are investigating. Use the probe function for testing. Try to include both *easy* sentences (where the model should do well) as well as *hard* sentences (where there are words in the context that might lead to confusion, or where the clue words are far away from the mask). For languages other than Dutch or English, make sure to include enough explanation so that examples and tests are clear to a non-native speaker.\n",
        "\n",
        "Describe how well the model did on your probe sentences. Where there any cases where the model made the wrong decision?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grammatical phenomenon:** Subject‚Äìadjective agreement in Italian. In Italian, adjectives must agree in gender (masculine/feminine) and number (singular/plural) with the noun they modify.\n",
        "\n",
        "**Objective:** Test whether the language model can correctly predict the form of an adjective given the subject, including cases where the correct agreement might be obscured by distractor words or complex sentence structures.\n",
        "\n",
        "**Design of the probe sentences:**\n",
        "\n",
        "I created five sentences with a [MASK] for the adjective. Some sentences are easy, where the subject and adjective are close and unambiguous. Some sentences are hard, where there are distractor nouns, negations, or compound subjects that may confuse the model. For each sentence, I provide a list of possible targets.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "‚ÄúLa casa √® [MASK].‚Äù ‚Üí target: *grande* (fem. sing.) ‚Üí tr. \"The house is [big].\"\n",
        "\n",
        "‚ÄúI fiori sono [MASK].‚Äù ‚Üí target: *colorati* (masc. pl.) ‚Üí tr. \"The flowers are [colorful].\"\n",
        "\n",
        "‚ÄúNonostante le nuvole scure, il cielo oggi sembra [MASK].‚Äù ‚Üí target: *sereno* (masc. sing.) ‚Üí tr. \"Despite the dark clouds, the sky looks [clear] today.\"\n",
        "\n",
        "‚ÄúLe ragazze del coro erano tutte [MASK].‚Äù ‚Üí target: *eleganti* (fem. pl.) ‚Üí tr. \"The choir girls were all [elegant].\"\n",
        "\n",
        "‚ÄúIl ragazzo e la ragazza sono [MASK].‚Äù ‚Üí target: *felici* (pl., masc+fem) ‚Üí tr. \"The boy and the girl are [happy].\""
      ],
      "metadata": {
        "id": "6rowOysiHrX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading an Italian BERT model for masked language modeling\n",
        "from transformers import pipeline\n",
        "\n",
        "italian_model = pipeline(\"fill-mask\", model=\"dbmdz/bert-base-italian-cased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOdn0sGROJeL",
        "outputId": "05f8f5c1-f11c-4090-9e18-4b881641895b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-italian-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGzEymX-2cnM",
        "outputId": "34b10de6-a80d-4b4f-aeb5-73e5de4572f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The specified target token `colorata` does not exist in the model vocabulary. Replacing with `colora`.\n",
            "The specified target token `sereno` does not exist in the model vocabulary. Replacing with `sere`.\n",
            "The specified target token `serene` does not exist in the model vocabulary. Replacing with `sere`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0090\ttoken: grande\tLa casa √® grande.\n",
            "0.0000\ttoken: grandi\tLa casa √® grandi.\n",
            "0.0011\ttoken: colorati\tI fiori sono colorati.\n",
            "0.0000\ttoken: colorate\tI fiori sono colorate.\n",
            "0.0000\ttoken: colorato\tI fiori sono colorato.\n",
            "0.0000\ttoken: colora\tI fiori sono colora.\n",
            "0.0008\ttoken: serena\tNonostante le nuvole scure, il cielo oggi sembra serena.\n",
            "0.0000\ttoken: sere\tNonostante le nuvole scure, il cielo oggi sembra sere.\n",
            "0.0000\ttoken: sereni\tNonostante le nuvole scure, il cielo oggi sembra sereni.\n",
            "0.0020\ttoken: eleganti\tLe ragazze del coro erano tutte eleganti.\n",
            "0.0000\ttoken: elegante\tLe ragazze del coro erano tutte elegante.\n",
            "0.0455\ttoken: felici\tIl ragazzo e la ragazza sono felici.\n",
            "0.0007\ttoken: felice\tIl ragazzo e la ragazza sono felice.\n"
          ]
        }
      ],
      "source": [
        "# Probe function\n",
        "def probe(sentence: str, targets: list):\n",
        "    for res in italian_model(sentence, targets=targets):\n",
        "        print(f\"{res['score']:6.4f}\\ttoken: {res['token_str']}\\t{res['sequence']}\")\n",
        "\n",
        "# Probe sentences\n",
        "probe('La casa √® [MASK].', ['grande', 'grandi'])\n",
        "probe('I fiori sono [MASK].', ['colorato', 'colorata', 'colorati', 'colorate'])\n",
        "probe('Nonostante le nuvole scure, il cielo oggi sembra [MASK].', ['sereno', 'serena', 'sereni', 'serene'])\n",
        "probe('Le ragazze del coro erano tutte [MASK].', ['elegante', 'eleganti'])\n",
        "probe('Il ragazzo e la ragazza sono [MASK].', ['felice', 'felici'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Italian BERT model correctly predicted adjective agreement in most cases. It performed well on simple sentences where the subject and adjective were close (‚ÄúLa casa √® [MASK]‚Äù) and also handled plural agreement correctly (‚ÄúI fiori sono [MASK]‚Äù).\n",
        "\n",
        "The model also correctly applied the masculine plural rule in compound subjects (‚ÄúIl ragazzo e la ragazza sono [MASK]‚Äù), showing that it has learned agreement rules beyond simple proximity.\n",
        "\n",
        "However, the model failed in the sentence with a distractor (‚ÄúNonostante le nuvole scure, il cielo oggi sembra [MASK]‚Äù). It incorrectly selected the feminine form ‚Äúserena‚Äù instead of the correct masculine ‚Äúsereno‚Äù, maybe because the nearby noun ‚Äúnuvole‚Äù is feminine. This suggests that the model may rely on local cues rather than full syntactic structure in more complex sentences.\n",
        "\n",
        "Overall, the model captures basic agreement patterns but can be misled by intervening nouns."
      ],
      "metadata": {
        "id": "weRIEcsSOvPg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qWoOqEb2cnN"
      },
      "source": [
        "## Exercise 2: Mixing Pipelines for Text-to-text QA in Many Languages\n",
        "\n",
        "The Model Hub of HuggingFace is home to a staggering amount of models for the more disparate use-cases, but you may have noticed that many of those are trained on the English language. Let's consider for example the [`UnifiedQA`](https://github.com/allenai/unifiedqa) model by AllenAI, which is a T5 model architecture trained to perform question answering on multiple formats (e.g. extract the answer from the provided context, produce an answer without a supporting context, choose among multiple possible answers, yes/no questions) using a unified text-to-text approach. While this opens thrilling perspectives in having a single model for all QA use-cases, UnifiedQA models are available for English only, and training such models from scratch in another language would require nontrivial effort and resources.\n",
        "\n",
        "Here are several examples of how text should be formatted for the UnifiedQA model:\n",
        "\n",
        "| **Task type** | **Example Dataset** | **Format** | **Example** | **Output** |\n",
        "| :---: | :--- | :--- | :--- | :--- |\n",
        "|  **Extractive QA** | SQUAD | `<QUESTION> \\n <CONTEXT>` | `At what speed did the turbine operate? \\n (Nikola_Tesla) On his 50th birthday in 1906, Tesla demonstrated his 200 horsepower (150 kilowatts) 16,000 rpm bladeless turbine. ...` |  `16,000 rpm` |\n",
        "|  **Abstractive QA** | NarrativeQA | `<QUESTION> \\n <CONTEXT>` | `What does a drink from narcissus's spring cause the drinker to do?  \\n  Mercury has awakened Echo, who weeps for Narcissus, and states that a drink from Narcissus's spring causes the drinkers to ''Grow dotingly enamored of themselves.'' ...` | `fall in love with themselves` |\n",
        "|  **Multiple-choice QA** | ARC-challenge | `<QUESTION> \\n (a) <CHOICE_A> (b) <CHOICE_B> ...` | `What does photosynthesis produce that helps plants grow? \\n (A) water (B) oxygen (C) protein (D) sugar` | `sugar` |\n",
        "|  **Multiple-choice QA with context** | MCTest | `<QUESTION> \\n (a) <CHOICE_A> (b) <CHOICE_B> ... \\n <CONTEXT>` | `Who was Billy? \\n (A) The skinny kid (B) A teacher (C) A little kid (D) The big kid \\n Billy was like a king on the school yard. A king without a queen. He was the biggest kid in our grade, so he made all the rules during recess. ...` | `The big kid` |\n",
        "|  **Yes-no QA** | BoolQ | `<QUESTION> \\n <CONTEXT>` | `Was America the first country to have a president?  \\n (President) The first usage of the word president to denote the highest official in a government was during the Commonwealth of England ...` | `no` |\n",
        "\n",
        "### Assignment\n",
        "\n",
        "We are gonna build a function making use of multiple models through ü§ó Pipelines to generate a response to a question in one of the formats specified above, in one of the languages supported by the MT systems available on the HuggingFace Model Hub. The function will translate and paraphrase the query into multiple examples, and then pick the best outputs of the UnifiedQA model as candidates for backtranslation. In this way, we mock the existance of a UnifiedQA model for the language of our choice.\n",
        "\n",
        "### Model\n",
        "\n",
        "The following code loads the UnifiedQA model and use it to perform QA on a multiple choice question without context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Tcbt5wzQ2cnN",
        "outputId": "350b51db-3fa4-4e62-ee65-4021f4119da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Paris'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Using at least the base variant of the model is advised for good results\n",
        "generator = pipeline(\"text2text-generation\", model=\"allenai/unifiedqa-t5-base\")\n",
        "generator(\"What is the name of the city where the Eiffel Tower is located? \\n (A) Paris (B) London (C) Prague (D) Berlin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKI5KAqE2cnN"
      },
      "source": [
        "### Your turn to Pipe\n",
        "\n",
        "Using the pipelines we saw in the tutorial, create a function taking a `question` string, an optional `context` string and an optional list of strings called `choices` and performs the following steps:\n",
        "\n",
        "- Use one of the [MarianMT](https://huggingface.co/models?search=helsinki-nlp) machine translation models to translate all the inputs from the language of your choice to English. You may want to split the text into sentences (e.g. by splitting on periods) to obtain better results for the context.\n",
        "\n",
        "- Use a paraphrasing model ([`tuner007/pegasus_paraphrase`](https://huggingface.co/tuner007/pegasus_paraphrase) is a good choice, albeit heavy) to produce 4 paraphrases of the question, using the `num_return_sequences` parameter.\n",
        "\n",
        "- For each question (translated + 4 paraphrases), format it with the translated context and choices (if present) as a single string in the format required by UnifiedQA.\n",
        "\n",
        "- Use the `allenai/unifiedqa-t5-base` model to generate an answer for each of the 5 questions.\n",
        "\n",
        "- If at least 3 of the 5 answers are identical strings, return the result translated back to the original language using the MarianMT model for the reciprocal language pair (e.g. if you used `Helsinki-NLP/opus-mt-nl-en` to translate from Dutch to English, you will need to use `Helsinki-NLP/opus-mt-en-nl`). Otherwise, print \"No common answer found\" translated in the original language.\n",
        "\n",
        "**Importantly**, the quality of the output does not determine your score in the evaluation. The goal is to get a feel for the models and their capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zqTDT-O02cnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "196607fb-9247-4cc0-8692-63b5d64db22a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from typing import Optional, List\n",
        "from collections import Counter\n",
        "\n",
        "# Models\n",
        "translator_to_en = pipeline(\"translation_it_to_en\", model=\"Helsinki-NLP/opus-mt-it-en\")\n",
        "translator_to_it = pipeline(\"translation_en_to_it\", model=\"Helsinki-NLP/opus-mt-en-it\")\n",
        "paraphraser = pipeline(\"text2text-generation\", model=\"tuner007/pegasus_paraphrase\")\n",
        "qa_model = pipeline(\"text2text-generation\", model=\"allenai/unifiedqa-t5-base\")\n",
        "\n",
        "def answer(question: str, context: Optional[str] = None, choices: Optional[List[str]] = None):\n",
        "    # 1. Translation of question, context and choices (from Italian to English)\n",
        "    en_question = translator_to_en(question)[0]['translation_text']\n",
        "\n",
        "    en_context = \"\"\n",
        "    if context:\n",
        "        sentences = context.split('. ')\n",
        "        en_context = \" \".join([t['translation_text'] for t in translator_to_en(sentences)])\n",
        "\n",
        "    en_choices = []\n",
        "    if choices:\n",
        "        en_choices = [t['translation_text'] for t in translator_to_en(choices)]\n",
        "\n",
        "    # 2. Paraphrases\n",
        "    paraphs = paraphraser(en_question, num_return_sequences=4, num_beams=4)\n",
        "    all_qs = [en_question] + [p['generated_text'] for p in paraphs]\n",
        "\n",
        "    # 3. Formatting for UnifiedQA (\"question \\n choice1 \\n choice2 \\n context\")\n",
        "    formatted_inputs = []\n",
        "    labeled_choices = [f\"({chr(97+i)}) {c}\" for i, c in enumerate(en_choices)]\n",
        "    choices_str = \" \".join(labeled_choices)\n",
        "\n",
        "    for q in all_qs:\n",
        "        input_str = f\"{q} \\n {choices_str}\"\n",
        "        if en_context:\n",
        "            input_str += f\" \\n {en_context}\"\n",
        "        formatted_inputs.append(input_str)\n",
        "\n",
        "    # 4. Generating answers\n",
        "    answers = [qa_model(i)[0]['generated_text'] for i in formatted_inputs]\n",
        "\n",
        "    # 5. Majority check (at least 3 answers out of 5 must be identical)\n",
        "    counts = Counter(answers)\n",
        "    most_common, count = counts.most_common(1)[0]\n",
        "\n",
        "    if count >= 3:\n",
        "        final = translator_to_it(most_common)[0]['translation_text']\n",
        "    else:\n",
        "        final = translator_to_it(\"No common answer found\")[0]['translation_text']\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final,\n",
        "        \"paraphrases\": all_qs[1:],\n",
        "        \"answers\": answers,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test question\n",
        "question = \"Quale tra queste citt√† √® famosa per il Colosseo?\"\n",
        "context = \"Il Colosseo √® un antico anfiteatro situato nel centro della capitale italiana.\"\n",
        "choices = [\"Milano\", \"Firenze\", \"Roma\", \"Napoli\"]\n",
        "\n",
        "result = answer(question, context=context, choices=choices)\n",
        "\n",
        "print(f\"Final answer: {result['final_answer']}\")\n",
        "\n",
        "paraphrases = result.get(\"paraphrases\", [])\n",
        "print(f\"\\nGenerated paraphrases:\")\n",
        "for i, p in enumerate(paraphrases, 1):\n",
        "    print(f\"  {i}: {p}\")\n",
        "\n",
        "print(\"\\nAnswers given by UnifiedQA (in English) for each paraphrase:\")\n",
        "print(result.get(\"all_answers_en\", result.get(\"answers\", \"Key not found\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W16kNRfnG69j",
        "outputId": "74143b7c-488c-4114-8a45-05e979f60d6c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final answer: Roma\n",
            "\n",
            "Generated paraphrases:\n",
            "  1: Which city is famous for the Colosseum?\n",
            "  2: Which city is known for the Colosseum?\n",
            "  3: Which of these cities is known for the Colosseum?\n",
            "  4: Which of these cities is known for its Colosseum?\n",
            "\n",
            "Answers given by UnifiedQA (in English) for each paraphrase:\n",
            "['Rome', 'Naples', 'Naples', 'Rome', 'Rome']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpM0oApk2cnN"
      },
      "source": [
        "## (Optional) Exercise 3: SentenceTransformers for Semantic Similarity Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbtJvk1k2cnN"
      },
      "source": [
        "*Figures and some code are from the [CohereAI Semantic Search Tutorial](https://docs.cohere.ai/semantic-search/) by Jay Alammar.*\n",
        "\n",
        "> SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. The initial work is described in our paper [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084).\n",
        ">\n",
        "> You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.\n",
        ">\n",
        "> The framework is based on PyTorch and Transformers and offers a large collection of pre-trained models tuned for various tasks. Further, it is easy to fine-tune your own models.\n",
        "\n",
        "Semantic search is a typical use case in natural language processing, in which we want to retrieve the most relevant documents from a corpus (e.g. Automatic FAQs, Web browser search results, etc.). Using the similarity between embedded text representations allows us to go beyond simple keyword matching, which is highly desirable in this setting (e.g. `tomorrow will rain` should be very close in embedding space to `the weather forecast announces showers for the next day`, despite no lexical overlap).\n",
        "\n",
        "<div>\n",
        "<img alt=\"Visualizing Semantic Search\" src=\"https://github.com/cohere-ai/notebooks/raw/main/notebooks/images/basic-semantic-search-overview.png?3\" style=\"width: 60%\" />\n",
        "</div>\n",
        "\n",
        "In this exercise we will use first Huggingface Transformers and then the [SentenceTransformers](https://sbert.net) library to find the most relevant paragraphs for a specific query.\n",
        "\n",
        "Let's start by loading the `train` split of the `squad` dataset from the Dataset Hub and flatten its structure so that every example contains a single triplet `(context, question, answer)`. We are going to use only the first 50 rows of the dataset, the others can be discarded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fa5XQv2O2cnO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "3ab75553d4eb4e31a8bb3622342be77a",
            "3780703815444e24bdd254f0927037dc",
            "487ccf66e78c483b801ae7e47f9b2b39",
            "eb3fe4af10b14da9bb41599289fecc1e",
            "7b9f13c84f3b4360bcc463323f6072b0",
            "81806599e0584718ad2203a66be82268",
            "4e6dda282e634ccea43b249172659cbc",
            "1c95c00257374e119bf63e1c2b95b1cc",
            "d6e6c8c9896a431283e2d46287c34684",
            "6cb71a83aafc49b491daf88a9ac96a77",
            "144e3079435e4befbf89846273783775",
            "df1236e16bfc40348d0cb552d19181a4",
            "9d4fba7e5a04472481c25746c107accc",
            "687522956c69462a90b213ede6a3ad2d",
            "a260e500c8b042e09898dba981ea8597",
            "5846f4f10b4146998420773013e43851",
            "b2b347963fee48acaa3effa65e7473e3",
            "ec1750eaebec4a718a9c3a5a5308dc5f",
            "956837bb7784432b9e7fe75f24a9d036",
            "c9e12f6a43784842ac70b842f314baa8",
            "bc33821981184ef99648a78e7bb8f5f6",
            "e9a4e7ae5d8d4466a61c003b7e501c8d",
            "6ee531a45f54490d992ce2bb067268b7",
            "908a336547fd4f30af7173316fdea50d",
            "ea6bc3fb798d4889ab0e946610f7d739",
            "dc2194d9309d421aa14a36e5a563c3af",
            "aad706015cd349d2b7a86c2997249bf0",
            "796d2cd8f90f448a8430c64f9dd0b63e",
            "89dbd67127ef4732886cefe3d6e5d84c",
            "9a847bbf2f854b998add7cbab17f9006",
            "81789261c1434e93b2d37083e1551eb9",
            "9d00d921d23a4f6d99bed9b99edaedb8",
            "4172dbefbe824ebf95eab71d1a41cda5",
            "fbb35c4701974f8981808e8d9a92d215",
            "f535d3ca20f34718a899aed621f89515",
            "eeddfa3df45040199eb783c6ca3bef6e",
            "56361ef69bf04ee883517c07612ae216",
            "ef74c12c49d14adca025d9fe48383bcc",
            "aeae02bc787b4f2ea83bfc4df2d8751e",
            "33afe9556a6045ffa9607a98b832af4b",
            "6f0912bdbeae48a6a4c3fc9dcaf0cf00",
            "f53d404ad285428689c6b4335e309f40",
            "e27ab5a0a53847ff8f8b321775f95bd5",
            "ecd8a9523c114339a0483e907215523e",
            "4f503b7c5ea24720a89ed2b9bfb46b2a",
            "7442a44173504e14b0f3268a3e3f7c82",
            "fb64ec945dca4d048bf5ccde3e36bc80",
            "f15d2a0c37c84bce8cd39802f090283f",
            "ddd882a7b381433e82430778149ea093",
            "504a7ad30baf4c5eb1d0c1e378ded58f",
            "897028855b58480e827850b5c07bd69c",
            "6dd0ab9ee3134e4baa563327dcbd7e5d",
            "d8b4f702eebd451fa9313996b02ba6a0",
            "0fbc8f8d6a7e4bb889ed74c9d61b725c",
            "0a59597beba3445ca1b370775f413b29"
          ]
        },
        "outputId": "0896a259-26cb-45f1-c1f3-197bfeae99c7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ab75553d4eb4e31a8bb3622342be77a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df1236e16bfc40348d0cb552d19181a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/validation-00000-of-00001.par(‚Ä¶):   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ee531a45f54490d992ce2bb067268b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbb35c4701974f8981808e8d9a92d215"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f503b7c5ea24720a89ed2b9bfb46b2a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "squad = load_dataset(\"squad\", split=\"train[:50]\")\n",
        "\n",
        "squad_train_filtered = None# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWs07qSq2cnO"
      },
      "source": [
        "Now, sample a question at random from the resulting dataset and print it. You can use `shuffle` or turn the Dataset into a `DataFrame` and use `sample`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ntmPNg6T2cnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0d8440-7f4b-42c4-9084-2f12cc5da28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "query = None # Your code here\n",
        "\n",
        "print(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqj7Itty2cnO"
      },
      "source": [
        "We now going to use a model trained to perform **semantic search** to retrieve the top 10 most likely contexts for each selected question.\n",
        "\n",
        "The model `sentence-transformers/multi-qa-MiniLM-L6-cos-v1` is a good choice for this task, since it is relatively small and was explicitly trained for semantic search. We are going to define now three utility functions:\n",
        "\n",
        "- `dot_score` computes the dot product between two Pytorch tensors.\n",
        "- `mean_pooling` averages the embeddings produced by a model to obtain a **sentence embedding**.\n",
        "- `encode` uses a model and a tokenizer to convert a list of texts into a tensor of embeddings. **Complete it with the first two steps we saw in the tutorial.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5jKiqYW82cnO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def dot_score(a: Tensor, b: Tensor):\n",
        "    \"\"\"\n",
        "    Computes the dot-product dot_prod(a[i], b[j]) for all i and j.\n",
        "    :return: Matrix with res[i][j]  = dot_prod(a[i], b[j])\n",
        "    Taken from the SentenceTransformer library\n",
        "    \"\"\"\n",
        "    if not isinstance(a, torch.Tensor):\n",
        "        a = torch.tensor(a)\n",
        "    if not isinstance(b, torch.Tensor):\n",
        "        b = torch.tensor(b)\n",
        "    if len(a.shape) == 1:\n",
        "        a = a.unsqueeze(0)\n",
        "    if len(b.shape) == 1:\n",
        "        b = b.unsqueeze(0)\n",
        "    print(a.shape, b.shape)\n",
        "    # Compute the dot-product\n",
        "    return torch.mm(a, b.transpose(0, 1))\n",
        "\n",
        "\n",
        "#Mean Pooling - Average all the embeddings produced by the model\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    # First element of model_output contains all token embeddings\n",
        "    token_embeddings = model_output.last_hidden_state\n",
        "    # Expand the mask to the same size as the token embeddings to avoid indexing errors\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    # Compute the mean of the token embeddings\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "\n",
        "#Encode text\n",
        "def encode(model, tokenizer, texts):\n",
        "    # Tokenize sentences\n",
        "    encoded_input = None # Your code here\n",
        "    # Compute token embeddings\n",
        "    with torch.no_grad():\n",
        "        model_output = None # Your code here\n",
        "    # Perform pooling\n",
        "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "    # Normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1a-TYHk2cnO"
      },
      "source": [
        "Let's now use these functions to compute similarity scores for the query and all the contexts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7DKASRkU2cnO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "0cd48dbf-ddfe-481c-d348-243bc2a4da04"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'to_pandas'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1580269110.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sentences we want sentence embeddings for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquad_train_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the model and tokenizer from HuggingFace Hub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;31m# Your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_pandas'"
          ]
        }
      ],
      "source": [
        "# Sentences we want sentence embeddings for\n",
        "contexts = list(squad_train_filtered.to_pandas()['context'])\n",
        "\n",
        "# Load the model and tokenizer from HuggingFace Hub\n",
        "tokenizer = None # Your code here\n",
        "model = None # Your code here\n",
        "\n",
        "#Encode query and contexts with the encode function\n",
        "query_emb = None # Your code here\n",
        "contexts_emb = None # Your code here\n",
        "\n",
        "#Compute dot score between query and all contexts embeddings\n",
        "scores = torch.mm(query_emb, contexts_emb.transpose(0, 1))[0].cpu().tolist()\n",
        "\n",
        "#Combine contexts & scores\n",
        "contexts_score_pairs = list(zip(contexts, scores))\n",
        "\n",
        "#Sort by decreasing score\n",
        "contexts_score_pairs = sorted(contexts_score_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#Output passages & scores\n",
        "for ctx, score in contexts_score_pairs:\n",
        "    print(score, ctx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2OYeADm2cnP"
      },
      "source": [
        "We can now use SentenceTransformers to do the same, but using much less code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhBiDyBA2cnP"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Query was defined above\n",
        "contexts = list(squad_train_filtered.to_pandas()['context'])\n",
        "\n",
        "#Load the model\n",
        "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
        "\n",
        "#Encode query and contexts using SentenceTransformer model.encode\n",
        "query_emb = model.encode(query)\n",
        "contexts_emb = model.encode(contexts)\n",
        "\n",
        "#Compute dot score between query and all contexts embeddings\n",
        "scores = util.dot_score(query_emb, contexts_emb)[0].tolist()\n",
        "\n",
        "#Combine contexts & scores\n",
        "contexts_score_pairs = list(zip(contexts, scores))\n",
        "\n",
        "#Sort by decreasing score\n",
        "contexts_score_pairs = sorted(contexts_score_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#Output passages & scores\n",
        "for ctx, score in contexts_score_pairs:\n",
        "    print(score, ctx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADOnzbZ_2cnP"
      },
      "source": [
        "For a more advanced overview on how to optimize speed with semantic search, see how to use the [FAISS](https://github.com/facebookresearch/faiss) library to perform fast nearest neighbor search natively with Huggingface Transformers here: [Using FAISS for efficient similarity search ](https://huggingface.co/course/chapter5/6?fw=pt#using-faiss-for-efficient-similarity-search)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
      }
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0f988cf7197404faf5aac72ae62e866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9694b1fa14504b5497b823e7de0646e1",
              "IPY_MODEL_fb76fc908fb1469c8d6df54ac197a232",
              "IPY_MODEL_7fe65ccc8bbf4f738f8e1ca5af6e78f3"
            ],
            "layout": "IPY_MODEL_d629e785c17c4ba69ba00e73b7f394d9"
          }
        },
        "9694b1fa14504b5497b823e7de0646e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_396f6306cc7748b994e1decf7235d496",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4feea6cfb86a47e9ae57472fbe39a64a",
            "value": ""
          }
        },
        "fb76fc908fb1469c8d6df54ac197a232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e996e4bc26c84bafb85f7119b374faf7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_633b68242ae94a249851b14a2e5afbd0",
            "value": 0
          }
        },
        "7fe65ccc8bbf4f738f8e1ca5af6e78f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab76d8cb571a4bb381feffd64900529e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a98d84f44ec44ac0b9816ad9d4893068",
            "value": "‚Äá0/0‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "d629e785c17c4ba69ba00e73b7f394d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396f6306cc7748b994e1decf7235d496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4feea6cfb86a47e9ae57472fbe39a64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e996e4bc26c84bafb85f7119b374faf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "633b68242ae94a249851b14a2e5afbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab76d8cb571a4bb381feffd64900529e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98d84f44ec44ac0b9816ad9d4893068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ab75553d4eb4e31a8bb3622342be77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3780703815444e24bdd254f0927037dc",
              "IPY_MODEL_487ccf66e78c483b801ae7e47f9b2b39",
              "IPY_MODEL_eb3fe4af10b14da9bb41599289fecc1e"
            ],
            "layout": "IPY_MODEL_7b9f13c84f3b4360bcc463323f6072b0"
          }
        },
        "3780703815444e24bdd254f0927037dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81806599e0584718ad2203a66be82268",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4e6dda282e634ccea43b249172659cbc",
            "value": "README.md:‚Äá"
          }
        },
        "487ccf66e78c483b801ae7e47f9b2b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c95c00257374e119bf63e1c2b95b1cc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6e6c8c9896a431283e2d46287c34684",
            "value": 1
          }
        },
        "eb3fe4af10b14da9bb41599289fecc1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb71a83aafc49b491daf88a9ac96a77",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_144e3079435e4befbf89846273783775",
            "value": "‚Äá7.62k/?‚Äá[00:00&lt;00:00,‚Äá423kB/s]"
          }
        },
        "7b9f13c84f3b4360bcc463323f6072b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81806599e0584718ad2203a66be82268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6dda282e634ccea43b249172659cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c95c00257374e119bf63e1c2b95b1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d6e6c8c9896a431283e2d46287c34684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cb71a83aafc49b491daf88a9ac96a77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "144e3079435e4befbf89846273783775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df1236e16bfc40348d0cb552d19181a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d4fba7e5a04472481c25746c107accc",
              "IPY_MODEL_687522956c69462a90b213ede6a3ad2d",
              "IPY_MODEL_a260e500c8b042e09898dba981ea8597"
            ],
            "layout": "IPY_MODEL_5846f4f10b4146998420773013e43851"
          }
        },
        "9d4fba7e5a04472481c25746c107accc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2b347963fee48acaa3effa65e7473e3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ec1750eaebec4a718a9c3a5a5308dc5f",
            "value": "plain_text/train-00000-of-00001.parquet:‚Äá100%"
          }
        },
        "687522956c69462a90b213ede6a3ad2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_956837bb7784432b9e7fe75f24a9d036",
            "max": 14458314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9e12f6a43784842ac70b842f314baa8",
            "value": 14458314
          }
        },
        "a260e500c8b042e09898dba981ea8597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc33821981184ef99648a78e7bb8f5f6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e9a4e7ae5d8d4466a61c003b7e501c8d",
            "value": "‚Äá14.5M/14.5M‚Äá[00:00&lt;00:00,‚Äá17.7MB/s]"
          }
        },
        "5846f4f10b4146998420773013e43851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b347963fee48acaa3effa65e7473e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec1750eaebec4a718a9c3a5a5308dc5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "956837bb7784432b9e7fe75f24a9d036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9e12f6a43784842ac70b842f314baa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc33821981184ef99648a78e7bb8f5f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9a4e7ae5d8d4466a61c003b7e501c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ee531a45f54490d992ce2bb067268b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_908a336547fd4f30af7173316fdea50d",
              "IPY_MODEL_ea6bc3fb798d4889ab0e946610f7d739",
              "IPY_MODEL_dc2194d9309d421aa14a36e5a563c3af"
            ],
            "layout": "IPY_MODEL_aad706015cd349d2b7a86c2997249bf0"
          }
        },
        "908a336547fd4f30af7173316fdea50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_796d2cd8f90f448a8430c64f9dd0b63e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_89dbd67127ef4732886cefe3d6e5d84c",
            "value": "plain_text/validation-00000-of-00001.par(‚Ä¶):‚Äá100%"
          }
        },
        "ea6bc3fb798d4889ab0e946610f7d739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a847bbf2f854b998add7cbab17f9006",
            "max": 1819889,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81789261c1434e93b2d37083e1551eb9",
            "value": 1819889
          }
        },
        "dc2194d9309d421aa14a36e5a563c3af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d00d921d23a4f6d99bed9b99edaedb8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4172dbefbe824ebf95eab71d1a41cda5",
            "value": "‚Äá1.82M/1.82M‚Äá[00:00&lt;00:00,‚Äá14.6MB/s]"
          }
        },
        "aad706015cd349d2b7a86c2997249bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796d2cd8f90f448a8430c64f9dd0b63e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89dbd67127ef4732886cefe3d6e5d84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a847bbf2f854b998add7cbab17f9006": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81789261c1434e93b2d37083e1551eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d00d921d23a4f6d99bed9b99edaedb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4172dbefbe824ebf95eab71d1a41cda5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbb35c4701974f8981808e8d9a92d215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f535d3ca20f34718a899aed621f89515",
              "IPY_MODEL_eeddfa3df45040199eb783c6ca3bef6e",
              "IPY_MODEL_56361ef69bf04ee883517c07612ae216"
            ],
            "layout": "IPY_MODEL_ef74c12c49d14adca025d9fe48383bcc"
          }
        },
        "f535d3ca20f34718a899aed621f89515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeae02bc787b4f2ea83bfc4df2d8751e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_33afe9556a6045ffa9607a98b832af4b",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "eeddfa3df45040199eb783c6ca3bef6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0912bdbeae48a6a4c3fc9dcaf0cf00",
            "max": 87599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f53d404ad285428689c6b4335e309f40",
            "value": 87599
          }
        },
        "56361ef69bf04ee883517c07612ae216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e27ab5a0a53847ff8f8b321775f95bd5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ecd8a9523c114339a0483e907215523e",
            "value": "‚Äá87599/87599‚Äá[00:00&lt;00:00,‚Äá261609.85‚Äáexamples/s]"
          }
        },
        "ef74c12c49d14adca025d9fe48383bcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeae02bc787b4f2ea83bfc4df2d8751e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33afe9556a6045ffa9607a98b832af4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f0912bdbeae48a6a4c3fc9dcaf0cf00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f53d404ad285428689c6b4335e309f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e27ab5a0a53847ff8f8b321775f95bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd8a9523c114339a0483e907215523e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f503b7c5ea24720a89ed2b9bfb46b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7442a44173504e14b0f3268a3e3f7c82",
              "IPY_MODEL_fb64ec945dca4d048bf5ccde3e36bc80",
              "IPY_MODEL_f15d2a0c37c84bce8cd39802f090283f"
            ],
            "layout": "IPY_MODEL_ddd882a7b381433e82430778149ea093"
          }
        },
        "7442a44173504e14b0f3268a3e3f7c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_504a7ad30baf4c5eb1d0c1e378ded58f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_897028855b58480e827850b5c07bd69c",
            "value": "Generating‚Äávalidation‚Äásplit:‚Äá100%"
          }
        },
        "fb64ec945dca4d048bf5ccde3e36bc80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd0ab9ee3134e4baa563327dcbd7e5d",
            "max": 10570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8b4f702eebd451fa9313996b02ba6a0",
            "value": 10570
          }
        },
        "f15d2a0c37c84bce8cd39802f090283f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fbc8f8d6a7e4bb889ed74c9d61b725c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0a59597beba3445ca1b370775f413b29",
            "value": "‚Äá10570/10570‚Äá[00:00&lt;00:00,‚Äá231332.90‚Äáexamples/s]"
          }
        },
        "ddd882a7b381433e82430778149ea093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "504a7ad30baf4c5eb1d0c1e378ded58f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "897028855b58480e827850b5c07bd69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dd0ab9ee3134e4baa563327dcbd7e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b4f702eebd451fa9313996b02ba6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fbc8f8d6a7e4bb889ed74c9d61b725c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a59597beba3445ca1b370775f413b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}